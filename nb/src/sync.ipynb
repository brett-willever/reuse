{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastapi aiohttp beautifulsoup4 google-cloud-storage\n",
    "\n",
    "import requests\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from typing import List\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "from google.cloud import storage\n",
    "\n",
    "TEMP_DIR: str = \"/tmp/pdfs\"\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "async def download_pdf(pdf_url: str) -> None:\n",
    "    pdf_filename = os.path.basename(pdf_url)\n",
    "    pdf_path = os.path.join(TEMP_DIR, pdf_filename)\n",
    "    logging.info(f\"Downloading {pdf_filename}...\")\n",
    "    start_time = time.time()\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(pdf_url) as response:\n",
    "            with open(pdf_path, \"wb\") as f:\n",
    "                while True:\n",
    "                    chunk = await response.content.read(1024)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    f.write(chunk)\n",
    "    end_time = time.time()\n",
    "    logging.info(f\"Downloaded {pdf_filename} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "async def download_pdfs(pdf_urls: List[str]) -> None:\n",
    "    logging.info(f\"Downloading {len(pdf_urls)} PDFs...\")\n",
    "    await asyncio.gather(*(download_pdf(url) for url in pdf_urls))\n",
    "\n",
    "\n",
    "def list_pdf_files() -> List[str]:\n",
    "    return [filename for filename in os.listdir(TEMP_DIR) if filename.endswith(\".pdf\")]\n",
    "\n",
    "\n",
    "async def upload_pdf(filename: str, gcs_bucket_name: str, prefix: str) -> None:\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(gcs_bucket_name)\n",
    "    blob = bucket.blob(f\"{prefix}/{filename}\")\n",
    "    logging.info(f\"Uploading {filename}...\")\n",
    "    start_time = time.time()\n",
    "    blob.upload_from_filename(os.path.join(TEMP_DIR, filename))\n",
    "    end_time = time.time()\n",
    "    logging.info(f\"Uploaded {filename} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "async def upload_to_gcs(pdf_filenames: List[str], gcs_bucket_name: str, prefix: str) -> None:\n",
    "    logging.info(f\"Uploading {len(pdf_filenames)} PDFs to Google Cloud Storage...\")\n",
    "    await asyncio.gather(*(upload_pdf(filename, gcs_bucket_name, prefix) for filename in pdf_filenames))\n",
    "\n",
    "\n",
    "def cleanup_temporary_directory(pdf_filenames: List[str]) -> None:\n",
    "    for filename in pdf_filenames:\n",
    "        file_path = os.path.join(TEMP_DIR, filename)\n",
    "        os.remove(file_path)\n",
    "    os.rmdir(TEMP_DIR)\n",
    "    logging.info(\"Temporary directory cleaned up\")\n",
    "\n",
    "\n",
    "@app.post(\"/process-pdfs/\")\n",
    "async def process_pdfs(web_location: str, gcs_bucket_name: str, prefix: str) -> None:\n",
    "    # Create temporary directory if it doesn't exist\n",
    "    os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "    response = requests.get(web_location)\n",
    "    if response.status_code != 200:\n",
    "        raise HTTPException(status_code=500, detail=\"Failed to fetch web location\")\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    links = soup.find_all(\"a\", href=True)\n",
    "    pdf_urls = [web_location + link[\"href\"] for link in links if link[\"href\"].endswith(\".pdf\")]\n",
    "\n",
    "    await download_pdfs(pdf_urls)\n",
    "    pdf_filenames = list_pdf_files()\n",
    "    await upload_to_gcs(pdf_filenames, gcs_bucket_name, prefix)\n",
    "    cleanup_temporary_directory(pdf_filenames)\n",
    "    logging.info(\"PDF download and upload process completed\")\n",
    "    return {\"message\": \"PDF download and upload process completed successfully\"}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
